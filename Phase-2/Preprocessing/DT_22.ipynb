{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Preprocessed Solar Data Summary\n",
        "\n",
        "In this section, we load and inspect the preprocessed solar plant data (`preprocessed_solar_data.csv`). This data was cleaned, filtered, and made ready for modeling in the earlier steps (as described in the preprocessing notebook).\n",
        "\n",
        "### What this notebook will check:\n",
        "- Dataset shape (rows, columns)\n",
        "- Data types of columns\n",
        "- Presence of missing values\n",
        "- Unique values per column\n",
        "- Descriptive statistics for numerical + categorical data\n",
        "\n",
        " The aim is to ensure that the dataset is well-prepared before passing it into the ML model in `DT_23.ipynb`.\n"
      ],
      "metadata": {
        "id": "y7BIYhB0fpgw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYowhEqEeq2k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "file_path = \"Dataset 1.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show shape, columns, and first 5 rows\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "print(\"\\nSample rows:\\n\", df.head())\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "# Parse datetime column and set as index\n",
        "df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "\n",
        "# Check for parsing errors (any NaT values)\n",
        "parsing_errors = df['datetime'].isnull().sum()\n",
        "print(f\"Datetime parsing errors: {parsing_errors}\")\n",
        "\n",
        "# Set as index for time-series analysis\n",
        "df = df.set_index('datetime')\n",
        "\n",
        "# Check for duplicate timestamps\n",
        "duplicate_timestamps = df.index.duplicated().sum()\n",
        "print(f\"Duplicate timestamps: {duplicate_timestamps}\")\n",
        "\n",
        "# Show the first few rows with the new index\n",
        "print(df.head())\n",
        "# Solar Power Plant Data Column Grouping and Tagging\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# --- Load the CSV and parse datetime ---\n",
        "csv_path = 'Dataset 1.csv'  # <-- Update path if needed\n",
        "df = pd.read_csv(csv_path)\n",
        "df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "df = df.set_index('datetime')  # Set datetime as index\n",
        "\n",
        "# --- Column Group Definitions ---\n",
        "column_groups = {\n",
        "    # Meteorological Irradiance\n",
        "    \"irradiance_meteorological\": [\n",
        "        'meteorolgicas_em_03_02_gii', 'meteorolgicas_em_08_01_gii',\n",
        "        'meteorolgicas_em_03_02_ghi', 'meteorolgicas_em_08_01_ghi',\n",
        "        'meteorolgicas_em_08_01_gii_rear', 'meteorolgicas_em_03_02_gii_rear',\n",
        "    ],\n",
        "    \"irradiance_cells\": [\n",
        "        'celulas_ctin08_cc_08_1_ir_cel_1', 'celulas_ctin08_cc_08_2_ir_cel_1',\n",
        "        'celulas_ctin03_cc_03_1_ir_cel_1', 'celulas_ctin03_cc_03_2_ir_cel_1',\n",
        "        'celulas_ctin08_cc_08_2_ir_cel_2', 'celulas_ctin03_cc_03_2_ir_cel_2',\n",
        "        'celulas_ctin03_cc_03_1_ir_cel_2', 'celulas_ctin08_cc_08_1_ir_cel_2',\n",
        "    ],\n",
        "    \"tracking_deviation\": [\n",
        "        'meteorolgicas_em_03_02_desviacin_incidente', 'meteorolgicas_em_08_01_desviacin_incidente'\n",
        "    ],\n",
        "    \"temperature_ambient\": [\n",
        "        'meteorolgicas_em_03_02_t_amb', 'meteorolgicas_em_08_01_t_amb',\n",
        "        'celulas_ctin08_cc_08_2_t_amb', 'celulas_ctin03_cc_03_1_t_amb',\n",
        "        'celulas_ctin08_cc_08_1_t_amb', 'celulas_ctin03_cc_03_2_t_amb',\n",
        "    ],\n",
        "    \"temperature_module\": [\n",
        "        'celulas_ctin03_cc_03_1_t_mod', 'celulas_ctin08_cc_08_2_t_mod',\n",
        "        'celulas_ctin03_cc_03_2_t_mod', 'celulas_ctin08_cc_08_1_t_mod',\n",
        "    ],\n",
        "    \"temperature_datalogger\": [\n",
        "        'meteorolgicas_em_03_02_t_dlogger', 'meteorolgicas_em_08_01_t_dlogger'\n",
        "    ],\n",
        "    \"humidity\": [\n",
        "        'meteorolgicas_em_03_02_h_r', 'meteorolgicas_em_08_01_h_r'\n",
        "    ],\n",
        "    \"wind_speed\": [\n",
        "        'meteorolgicas_em_08_01_ws', 'meteorolgicas_em_03_02_ws',\n",
        "        'celulas_ctin03_cc_03_2_wind_speed', 'celulas_ctin08_cc_08_1_wind_speed',\n",
        "        'celulas_ctin08_cc_08_2_wind_speed', 'celulas_ctin03_cc_03_1_wind_speed',\n",
        "    ],\n",
        "    \"wind_direction\": [\n",
        "        'meteorolgicas_em_08_01_wd', 'meteorolgicas_em_03_02_wd'\n",
        "    ],\n",
        "    \"string_voltage\": [col for col in df.columns if 'pv_v' in col],\n",
        "    \"string_current_ct03_s8\": [\n",
        "        f'inversores_ctin03_strings_string8_pv_i{i}' for i in range(1, 14)\n",
        "    ],\n",
        "    \"string_current_ct03_s10\": [\n",
        "        f'inversores_ctin03_strings_string10_pv_i{i}' for i in range(1, 14)\n",
        "    ],\n",
        "    \"string_current_ct08_s9\": [\n",
        "        f'inversores_ctin08_strings_string9_pv_i{i}' for i in range(1, 14)\n",
        "    ],\n",
        "    \"string_current_ct08_s12\": [\n",
        "        f'inversores_ctin08_strings_string12_pv_i{i}' for i in range(1, 11)\n",
        "    ],\n",
        "    \"inverter_power_ac\": [\n",
        "        'inversores_ctin08_inv_08_08_p', 'inversores_ctin03_inv_03_03_p'\n",
        "    ],\n",
        "    \"inverter_power_dc\": [\n",
        "        'inversores_ctin03_inv_03_03_p_dc', 'inversores_ctin08_inv_08_08_p_dc'\n",
        "    ],\n",
        "    \"inverter_energy\": [\n",
        "        'inversores_ctin03_inv_03_03_eact_tot', 'inversores_ctin08_inv_08_08_eact_tot'\n",
        "    ],\n",
        "    \"tracker_position\": [\n",
        "        'seguidores_ct08_gcu081_t0808029_pos_obj', 'seguidores_ct08_gcu081_t0808029_pos_ang',\n",
        "        'seguidores_ct03_gcu031_t0308035_pos_ang', 'seguidores_ct03_gcu031_t0308035_pos_obj'\n",
        "    ],\n",
        "    \"tracker_mode\": [\n",
        "        'seguidores_ct08_gcu081_t0808029_workingmode', 'seguidores_ct03_gcu031_t0308035_workingmode'\n",
        "    ],\n",
        "    \"plant_power_control\": [\n",
        "        'ppc_consig_p', 'ppc_p_tot', 'ppc_eact_export', 'ppc_eact_imp'\n",
        "    ],\n",
        "    \"theoretical_power\": [\n",
        "        'ttr_potenciaproducible'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# --- Analysis Group Definitions ---\n",
        "analysis_groups = {\n",
        "    \"all_irradiance\": column_groups[\"irradiance_meteorological\"] + column_groups[\"irradiance_cells\"],\n",
        "    \"all_temperature\": column_groups[\"temperature_ambient\"] + column_groups[\"temperature_module\"] + column_groups[\"temperature_datalogger\"],\n",
        "    \"all_wind\": column_groups[\"wind_speed\"] + column_groups[\"wind_direction\"],\n",
        "    \"all_string_electrical\": (\n",
        "        column_groups[\"string_current_ct03_s8\"] +\n",
        "        column_groups[\"string_current_ct03_s10\"] +\n",
        "        column_groups[\"string_current_ct08_s9\"] +\n",
        "        column_groups[\"string_current_ct08_s12\"] +\n",
        "        column_groups[\"string_voltage\"]\n",
        "    ),\n",
        "    \"all_power\": (\n",
        "        column_groups[\"inverter_power_ac\"] +\n",
        "        column_groups[\"inverter_power_dc\"] +\n",
        "        column_groups[\"plant_power_control\"] +\n",
        "        column_groups[\"theoretical_power\"]\n",
        "    ),\n",
        "    \"all_tracker\": column_groups[\"tracker_position\"] + column_groups[\"tracker_mode\"],\n",
        "    \"environmental\": column_groups[\"temperature_ambient\"] + column_groups[\"humidity\"] + column_groups[\"wind_speed\"] + column_groups[\"wind_direction\"],\n",
        "    \"soiling_analysis\": column_groups[\"irradiance_cells\"] + column_groups[\"irradiance_meteorological\"],\n",
        "    \"tracking_analysis\": column_groups[\"tracking_deviation\"] + column_groups[\"tracker_position\"] + column_groups[\"tracker_mode\"]\n",
        "}\n",
        "\n",
        "# --- Functions for Column Access ---\n",
        "def get_columns(group_name):\n",
        "    \"\"\"Return existing columns for the given group name.\"\"\"\n",
        "    if group_name in column_groups:\n",
        "        return [col for col in column_groups[group_name] if col in df.columns]\n",
        "    elif group_name in analysis_groups:\n",
        "        return [col for col in analysis_groups[group_name] if col in df.columns]\n",
        "    else:\n",
        "        print(f\"Group '{group_name}' not found.\")\n",
        "        return []\n",
        "\n",
        "def get_subset_df(group_name, include_datetime=True):\n",
        "    \"\"\"Return a subset DataFrame for a given group.\"\"\"\n",
        "    cols = get_columns(group_name)\n",
        "    if include_datetime:\n",
        "        # Include datetime as index or column\n",
        "        return df[cols].copy().reset_index()  # Datetime becomes a column\n",
        "    else:\n",
        "        return df[cols].copy()\n",
        "\n",
        "# --- Display Column Group Info ---\n",
        "print(\"Available column groups:\")\n",
        "for group in column_groups:\n",
        "    real_cols = get_columns(group)\n",
        "    print(f\"  - {group}: {len(real_cols)} columns\")\n",
        "\n",
        "print(\"\\nAvailable analysis groups:\")\n",
        "for group in analysis_groups:\n",
        "    real_cols = get_columns(group)\n",
        "    print(f\"  - {group}: {len(real_cols)} columns\")\n",
        "\n",
        "# --- Example Usages ---\n",
        "irradiance_df = get_subset_df(\"all_irradiance\")\n",
        "print(f\"\\nIrradiance dataframe shape: {irradiance_df.shape}\")\n",
        "\n",
        "power_df = get_subset_df(\"all_power\")\n",
        "print(f\"Power dataframe shape: {power_df.shape}\")\n",
        "\n",
        "env_df = get_subset_df(\"environmental\")\n",
        "print(f\"Environmental dataframe shape: {env_df.shape}\")\n",
        "# 1. Show missing data counts for all columns\n",
        "missing_counts = df.isnull().sum().sort_values(ascending=False)\n",
        "print(\"Missing values per column:\\n\", missing_counts[missing_counts > 0])\n",
        "\n",
        "# 2. Show missing rates per group\n",
        "print(\"\\nMissing value summary by group:\")\n",
        "for group in column_groups:\n",
        "    cols = get_columns(group)\n",
        "    if cols:\n",
        "        missing_rate = df[cols].isnull().mean().mean() * 100\n",
        "        print(f\"  - {group}: {missing_rate:.2f}% average missing\")\n",
        "\n",
        "# --- 1. Drop columns with very high missingness (>95%) ---\n",
        "high_missing_cols = [col for col in df.columns if df[col].isnull().mean() > 0.95]\n",
        "df_cleaned = df.drop(columns=high_missing_cols)\n",
        "print(f\"Dropped columns with >95% missing: {high_missing_cols}\")\n",
        "\n",
        "# --- 2. Interpolate and fill low-missing columns (≤5%) ---\n",
        "low_missing_cols = [col for col in df_cleaned.columns if df_cleaned[col].isnull().mean() <= 0.05]\n",
        "df_cleaned[low_missing_cols] = (\n",
        "    df_cleaned[low_missing_cols]\n",
        "    .interpolate(method='linear', limit_direction='both')\n",
        "    .fillna(method='ffill')\n",
        "    .fillna(method='bfill')\n",
        ")\n",
        "\n",
        "# --- 3. Identify columns with moderate missingness (50–95%) ---\n",
        "mid_missing_cols = [col for col in df_cleaned.columns if 0.5 < df_cleaned[col].isnull().mean() <= 0.95]\n",
        "print(f\"Columns with 50–95% missing (inspect before deciding): {mid_missing_cols}\")\n",
        "\n",
        "# --- 4. Remove night data for operational analysis ---\n",
        "irr_col = 'meteorolgicas_em_03_02_ghi'  # Main irradiance column\n",
        "day_df = df_cleaned[df_cleaned[irr_col] > 5].copy()  # Keep rows with GHI > 5 W/m²\n",
        "print(f\"Shape after removing night data: {day_df.shape}\")\n",
        "\n",
        "# Now, day_df is ready for most solar performance and loss analyses!\n",
        "# Total rows before filtering\n",
        "total_rows = df_cleaned.shape[0]\n",
        "\n",
        "# Total rows after filtering (daytime only)\n",
        "day_rows = day_df.shape[0]\n",
        "\n",
        "# Nighttime rows dropped\n",
        "night_rows = total_rows - day_rows\n",
        "night_pct = night_rows / total_rows * 100\n",
        "\n",
        "print(f\"Total rows before filtering: {total_rows}\")\n",
        "print(f\"Total rows after removing night data: {day_rows}\")\n",
        "print(f\"Nighttime rows dropped: {night_rows} ({night_pct:.2f}%)\")\n",
        "# --- Basic Outlier Removal for Solar PV Data ---\n",
        "\n",
        "def clean_outliers(df, col, lower, upper):\n",
        "    \"\"\"\n",
        "    Sets values outside [lower, upper] to NaN for a given column.\n",
        "    Prints how many values were set to NaN.\n",
        "    \"\"\"\n",
        "    if col not in df.columns:\n",
        "        return df\n",
        "    before = df[col].isnull().sum()\n",
        "    df[col] = df[col].where(df[col].between(lower, upper), float('nan'))\n",
        "    after = df[col].isnull().sum()\n",
        "    print(f\"{col}: set {after-before} outliers to NaN\")\n",
        "    return df\n",
        "\n",
        "# --- Set physical ranges per group (customize for your plant if needed) ---\n",
        "outlier_limits = {\n",
        "    'irradiance': (0, 1400),       # W/m²\n",
        "    'temperature': (-10, 80),      # °C\n",
        "    'wind_speed': (0, 40),         # m/s\n",
        "    'humidity': (0, 100),          # %\n",
        "    'power': (0, 48000),           # kW (48 MW plant, change if needed)\n",
        "    'string_voltage': (0, 1500),   # V\n",
        "    'string_current': (0, 40),     # A\n",
        "}\n",
        "\n",
        "# --- Apply limits to relevant columns using your grouping functions ---\n",
        "\n",
        "# Irradiance\n",
        "for col in get_columns('all_irradiance'):\n",
        "    day_df = clean_outliers(day_df, col, *outlier_limits['irradiance'])\n",
        "\n",
        "# Temperature\n",
        "for col in get_columns('all_temperature'):\n",
        "    day_df = clean_outliers(day_df, col, *outlier_limits['temperature'])\n",
        "\n",
        "# Wind Speed\n",
        "for col in get_columns('wind_speed'):\n",
        "    day_df = clean_outliers(day_df, col, *outlier_limits['wind_speed'])\n",
        "\n",
        "# Humidity\n",
        "for col in get_columns('humidity'):\n",
        "    day_df = clean_outliers(day_df, col, *outlier_limits['humidity'])\n",
        "\n",
        "# Power (AC/DC/Theoretical)\n",
        "for col in get_columns('all_power'):\n",
        "    day_df = clean_outliers(day_df, col, *outlier_limits['power'])\n",
        "\n",
        "# String Voltages\n",
        "for col in get_columns('string_voltage'):\n",
        "    day_df = clean_outliers(day_df, col, *outlier_limits['string_voltage'])\n",
        "\n",
        "# String Currents (all current groups)\n",
        "string_current_cols = (\n",
        "    get_columns('string_current_ct03_s8') +\n",
        "    get_columns('string_current_ct03_s10') +\n",
        "    get_columns('string_current_ct08_s9') +\n",
        "    get_columns('string_current_ct08_s12')\n",
        ")\n",
        "for col in string_current_cols:\n",
        "    day_df = clean_outliers(day_df, col, *outlier_limits['string_current'])\n",
        "\n",
        "# --- Optional: Interpolate/fill after outlier removal if needed ---\n",
        "# day_df = day_df.interpolate(method='linear', limit_direction='both').fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "print(\"Basic outlier cleaning complete!\")\n",
        "# Fill all remaining NaN values in the cleaned daytime dataframe\n",
        "day_df = (\n",
        "    day_df\n",
        "    .interpolate(method='linear', limit_direction='both')\n",
        "    .fillna(method='ffill')\n",
        "    .fillna(method='bfill')\n",
        ")\n",
        "\n",
        "# Check if any NaNs remain\n",
        "nan_count = day_df.isnull().sum().sum()\n",
        "print(f\"Total NaNs remaining after filling: {nan_count}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SAVE PREPROCESSED DATA TO CSV FILE\n",
        "# =============================================================================\n",
        "print(\"\\n=== SAVING PREPROCESSED DATA ===\")\n",
        "\n",
        "# Save the cleaned and preprocessed daytime data to CSV\n",
        "output_filename = \"preprocessed_solar_data.csv\"\n",
        "day_df.to_csv(output_filename)\n",
        "print(f\"✅ Preprocessed data saved to: {output_filename}\")\n",
        "print(f\"   Shape: {day_df.shape}\")\n",
        "print(f\"   Date range: {day_df.index.min()} to {day_df.index.max()}\")\n",
        "\n",
        "# Optional: Also save a summary of the preprocessing steps\n",
        "summary_filename = \"preprocessing_summary.txt\"\n",
        "with open(summary_filename, 'w') as f:\n",
        "    f.write(\"SOLAR POWER PLANT DATA PREPROCESSING SUMMARY\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "    f.write(f\"Original dataset shape: {df.shape}\\n\")\n",
        "    f.write(f\"High missing columns dropped (>95%): {len(high_missing_cols)}\\n\")\n",
        "    f.write(f\"Night data rows removed: {night_rows} ({night_pct:.2f}%)\\n\")\n",
        "    f.write(f\"Final preprocessed shape: {day_df.shape}\\n\")\n",
        "    f.write(f\"Remaining NaN values: {nan_count}\\n\")\n",
        "    f.write(f\"Date range: {day_df.index.min()} to {day_df.index.max()}\\n\")\n",
        "    f.write(f\"\\nPreprocessed data saved to: {output_filename}\\n\")\n",
        "\n",
        "print(f\"✅ Preprocessing summary saved to: {summary_filename}\")\n",
        "\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Dataset Inspection Summary\n",
        "\n",
        "- The dataset contains a clean structure with expected rows, columns, and types.\n",
        "- Missing values have been checked; no critical gaps remain.\n",
        "- Numerical and categorical features are summarized, and ranges look valid.\n",
        "- Unique values give insight into categorical diversity and numerical variation.\n",
        "\n",
        "---\n",
        "\n",
        "###  **Next Step**\n",
        "This dataset is now ready for:\n",
        "- Feature engineering\n",
        "- Model training\n",
        "- Performance analysis\n",
        "\n",
        " You can proceed to use this dataset directly in the `DT_23.ipynb` model pipeline.\n"
      ],
      "metadata": {
        "id": "5MimpMNYfchg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "file_path = \"preprocessed_solar_data.csv\"  # Adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Basic shape\n",
        "print(f\"Number of Rows: {df.shape[0]}\")\n",
        "print(f\"Number of Columns: {df.shape[1]}\\n\")\n",
        "\n",
        "# Data types\n",
        "print(\"Column Data Types:\")\n",
        "print(df.dtypes.value_counts(), \"\\n\")\n",
        "\n",
        "# Null values\n",
        "print(\"Null Values Per Column:\")\n",
        "print(df.isnull().sum(), \"\\n\")\n",
        "\n",
        "# Unique values\n",
        "print(\"Unique Values Per Column:\")\n",
        "print(df.nunique(), \"\\n\")\n",
        "\n",
        "# Descriptive statistics for numerical columns\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(df.describe().T)\n",
        "\n",
        "# Descriptive stats for object (categorical) columns\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "if len(categorical_cols):\n",
        "    print(\"\\nCategorical Column Statistics:\")\n",
        "    print(df[categorical_cols].describe().T)\n"
      ],
      "metadata": {
        "id": "kugM04-7e-QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Final Note\n",
        "\n",
        "The dataset `preprocessed_solar_data.csv` has passed preliminary checks for:\n",
        "- Data integrity\n",
        "- Completeness\n",
        "- Basic statistical validity\n",
        "\n",
        " This provides a strong foundation for accurate solar power modeling and advanced analytics.\n",
        "\n",
        "➡ You can now confidently proceed with training predictive models, performing loss analyses, or creating visual dashboards.\n"
      ],
      "metadata": {
        "id": "JZ5Jcm7Mf5Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Team Information\n",
        "\n",
        "**Team Name:** DRAGON TECH  \n",
        "\n",
        "**Team Members:**\n",
        "- Sartaj Singh Virdi (`svirdi_be23@thapar.edu`)\n",
        "- Prabhpreet Singh (`psingh9_be23@thapar.edu`)\n",
        "- Gurkirat Singh (`gsingh9_be23@thapar.edu`)"
      ],
      "metadata": {
        "id": "Ex01WGOCgb6N"
      }
    }
  ]
}